package handler

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/difyz9/ytb2bili/internal/core"
	"github.com/difyz9/ytb2bili/internal/core/types"
	"github.com/google/generative-ai-go/genai"
	"google.golang.org/api/option"

	"github.com/gin-gonic/gin"
)

type ConfigHandler struct {
	BaseHandler
}

func NewConfigHandler(app *core.AppServer) *ConfigHandler {
	return &ConfigHandler{
		BaseHandler: BaseHandler{App: app},
	}
}

// RegisterRoutes æ³¨å†Œé…ç½®ç›¸å…³è·¯ç”±
func (h *ConfigHandler) RegisterRoutes(server *core.AppServer) {
	api := server.Engine.Group("/api/v1")

	config := api.Group("/config")
	{
		config.GET("/deepseek", h.getDeepSeekConfig)
		config.PUT("/deepseek", h.updateDeepSeekConfig)
		config.GET("/proxy", h.getProxyConfig)
		config.PUT("/proxy", h.updateProxyConfig)

		// OpenAIå…¼å®¹APIé…ç½®
		config.GET("/openai-compatible", h.getOpenAICompatibleConfig)
		config.PUT("/openai-compatible", h.updateOpenAICompatibleConfig)
		config.POST("/openai-compatible/test", h.testOpenAICompatibleAPI)
		config.GET("/openai-compatible/providers", h.getOpenAICompatibleProviders)

		// AIæœåŠ¡çŠ¶æ€
		config.GET("/ai-services/status", h.getAIServicesStatus)
		config.PUT("/ai-services/primary", h.setPrimaryAIService)

		// GeminiåŸç”Ÿé…ç½®ï¼ˆç”¨äºå…ƒæ•°æ®ç”Ÿæˆï¼‰
		config.GET("/gemini", h.getGeminiConfig)
		config.PUT("/gemini", h.updateGeminiConfig)
		config.POST("/gemini/validate", h.validateGeminiApiKeys)
		config.GET("/gemini/models", h.getGeminiModels)
	}
}

// DeepSeekConfigRequest DeepSeeké…ç½®è¯·æ±‚
type DeepSeekConfigRequest struct {
	Enabled   *bool   `json:"enabled,omitempty"`    // æ˜¯å¦å¯ç”¨ï¼ˆå¯é€‰ï¼‰
	ApiKey    *string `json:"api_key,omitempty"`    // API Keyï¼ˆå¯é€‰ï¼‰
	Model     *string `json:"model,omitempty"`      // æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
	Endpoint  *string `json:"endpoint,omitempty"`   // ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰
	Timeout   *int    `json:"timeout,omitempty"`    // è¶…æ—¶æ—¶é—´ï¼ˆå¯é€‰ï¼‰
	MaxTokens *int    `json:"max_tokens,omitempty"` // æœ€å¤§Tokenæ•°ï¼ˆå¯é€‰ï¼‰
}

// DeepSeekConfigResponse DeepSeeké…ç½®å“åº”
type DeepSeekConfigResponse struct {
	Enabled   bool   `json:"enabled"`
	ApiKey    string `json:"api_key"` // ä¸ºäº†å®‰å…¨åªè¿”å›éƒ¨åˆ†å­—ç¬¦
	Model     string `json:"model"`
	Endpoint  string `json:"endpoint"`
	Timeout   int    `json:"timeout"`
	MaxTokens int    `json:"max_tokens"`
}

// ProxyConfigRequest ä»£ç†é…ç½®è¯·æ±‚
type ProxyConfigRequest struct {
	UseProxy  *bool   `json:"useProxy,omitempty"`  // æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆå¯é€‰ï¼‰
	ProxyHost *string `json:"proxyHost,omitempty"` // ä»£ç†åœ°å€ï¼ˆå¯é€‰ï¼‰
}

// ProxyConfigResponse ä»£ç†é…ç½®å“åº”
type ProxyConfigResponse struct {
	UseProxy  bool   `json:"useProxy"`  // æ˜¯å¦ä½¿ç”¨ä»£ç†
	ProxyHost string `json:"proxyHost"` // ä»£ç†åœ°å€
}

// getDeepSeekConfig è·å–DeepSeeké…ç½®
func (h *ConfigHandler) getDeepSeekConfig(c *gin.Context) {
	config := h.App.Config.DeepSeekTransConfig
	if config == nil {
		c.JSON(http.StatusOK, gin.H{
			"code":    200,
			"message": "success",
			"data": DeepSeekConfigResponse{
				Enabled:   false,
				ApiKey:    "",
				Model:     "deepseek-chat",
				Endpoint:  "https://api.deepseek.com",
				Timeout:   60,
				MaxTokens: 4000,
			},
		})
		return
	}

	// éšè—å®Œæ•´çš„API Keyï¼Œåªæ˜¾ç¤ºå‰å‡ ä½å’Œåå‡ ä½
	apiKeyMasked := ""
	if config.ApiKey != "" {
		if len(config.ApiKey) > 10 {
			apiKeyMasked = config.ApiKey[:6] + "..." + config.ApiKey[len(config.ApiKey)-4:]
		} else {
			apiKeyMasked = "***"
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data": DeepSeekConfigResponse{
			Enabled:   config.Enabled,
			ApiKey:    apiKeyMasked,
			Model:     config.Model,
			Endpoint:  config.Endpoint,
			Timeout:   config.Timeout,
			MaxTokens: config.MaxTokens,
		},
	})
}

// updateDeepSeekConfig æ›´æ–°DeepSeeké…ç½®
func (h *ConfigHandler) updateDeepSeekConfig(c *gin.Context) {
	var req DeepSeekConfigRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid request body: " + err.Error(),
		})
		return
	}

	// ç¡®ä¿é…ç½®å¯¹è±¡å­˜åœ¨
	if h.App.Config.DeepSeekTransConfig == nil {
		h.App.Config.DeepSeekTransConfig = &types.DeepSeekTransConfig{
			Enabled:   false,
			ApiKey:    "",
			Model:     "deepseek-chat",
			Endpoint:  "https://api.deepseek.com",
			Timeout:   60,
			MaxTokens: 4000,
		}
	}

	config := h.App.Config.DeepSeekTransConfig

	// æ›´æ–°é…ç½®å­—æ®µï¼ˆåªæ›´æ–°æä¾›çš„å­—æ®µï¼‰
	if req.Enabled != nil {
		config.Enabled = *req.Enabled
		h.App.Logger.Infof("Updated DeepSeek enabled: %v", config.Enabled)
	}

	if req.ApiKey != nil {
		config.ApiKey = *req.ApiKey
		h.App.Logger.Infof("Updated DeepSeek API Key: %s", maskApiKey(*req.ApiKey))
	}

	if req.Model != nil {
		config.Model = *req.Model
		h.App.Logger.Infof("Updated DeepSeek model: %s", config.Model)
	}

	if req.Endpoint != nil {
		config.Endpoint = *req.Endpoint
		h.App.Logger.Infof("Updated DeepSeek endpoint: %s", config.Endpoint)
	}

	if req.Timeout != nil {
		config.Timeout = *req.Timeout
		h.App.Logger.Infof("Updated DeepSeek timeout: %d", config.Timeout)
	}

	if req.MaxTokens != nil {
		config.MaxTokens = *req.MaxTokens
		h.App.Logger.Infof("Updated DeepSeek max_tokens: %d", config.MaxTokens)
	}

	// ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
	if err := types.SaveConfig(h.App.Config); err != nil {
		h.App.Logger.Errorf("Failed to save config: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{
			"code":    500,
			"message": "Failed to save configuration: " + err.Error(),
		})
		return
	}

	// å®æ—¶æ›´æ–°åº”ç”¨æœåŠ¡å™¨çš„é…ç½®ï¼ˆä¸éœ€è¦é‡å¯ï¼‰
	h.App.Config.DeepSeekTransConfig = config
	h.App.Logger.Info("âœ… DeepSeek configuration updated and applied successfully (no restart required)")

	// è¿”å›æˆåŠŸå“åº”
	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "Configuration updated and applied successfully (no restart required)",
		"data": DeepSeekConfigResponse{
			Enabled:   config.Enabled,
			ApiKey:    maskApiKey(config.ApiKey),
			Model:     config.Model,
			Endpoint:  config.Endpoint,
			Timeout:   config.Timeout,
			MaxTokens: config.MaxTokens,
		},
	})
}

// getProxyConfig è·å–ä»£ç†é…ç½®
func (h *ConfigHandler) getProxyConfig(c *gin.Context) {
	// æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦æœ‰ä»£ç†é…ç½®
	proxyConfig := h.App.Config.ProxyConfig
	if proxyConfig == nil {
		c.JSON(http.StatusOK, gin.H{
			"code":    200,
			"message": "success",
			"data": ProxyConfigResponse{
				UseProxy:  false,
				ProxyHost: "",
			},
		})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data": ProxyConfigResponse{
			UseProxy:  proxyConfig.UseProxy,
			ProxyHost: proxyConfig.ProxyHost,
		},
	})
}

// updateProxyConfig æ›´æ–°ä»£ç†é…ç½®
func (h *ConfigHandler) updateProxyConfig(c *gin.Context) {
	var req ProxyConfigRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid request body: " + err.Error(),
		})
		return
	}

	// ç¡®ä¿é…ç½®å¯¹è±¡å­˜åœ¨
	if h.App.Config.ProxyConfig == nil {
		h.App.Config.ProxyConfig = &types.ProxyConfig{
			UseProxy:  false,
			ProxyHost: "",
		}
	}

	config := h.App.Config.ProxyConfig

	// æ›´æ–°é…ç½®å­—æ®µï¼ˆåªæ›´æ–°æä¾›çš„å­—æ®µï¼‰
	if req.UseProxy != nil {
		config.UseProxy = *req.UseProxy
		h.App.Logger.Infof("Updated proxy enabled: %v", config.UseProxy)
	}

	if req.ProxyHost != nil {
		config.ProxyHost = *req.ProxyHost
		h.App.Logger.Infof("Updated proxy host: %s", config.ProxyHost)
	}

	// ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
	if err := types.SaveConfig(h.App.Config); err != nil {
		h.App.Logger.Errorf("Failed to save config: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{
			"code":    500,
			"message": "Failed to save configuration: " + err.Error(),
		})
		return
	}

	// å®æ—¶æ›´æ–°åº”ç”¨æœåŠ¡å™¨çš„é…ç½®ï¼ˆä¸éœ€è¦é‡å¯ï¼‰
	h.App.Config.ProxyConfig = config
	h.App.Logger.Info("âœ… Proxy configuration updated and applied successfully (no restart required)")

	// è¿”å›æˆåŠŸå“åº”
	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "Configuration updated and applied successfully (no restart required)",
		"data": ProxyConfigResponse{
			UseProxy:  config.UseProxy,
			ProxyHost: config.ProxyHost,
		},
	})
}

// maskApiKey éšè—API Keyçš„æ•æ„Ÿä¿¡æ¯
func maskApiKey(apiKey string) string {
	if apiKey == "" {
		return ""
	}
	if len(apiKey) > 10 {
		return apiKey[:6] + "..." + apiKey[len(apiKey)-4:]
	}
	return "***"
}

// ========== OpenAIå…¼å®¹APIé…ç½® ==========

// OpenAICompatibleConfigRequest OpenAIå…¼å®¹APIé…ç½®è¯·æ±‚
type OpenAICompatibleConfigRequest struct {
	Enabled     *bool    `json:"enabled,omitempty"`
	Provider    *string  `json:"provider,omitempty"`
	ApiKey      *string  `json:"api_key,omitempty"`
	BaseURL     *string  `json:"base_url,omitempty"`
	Model       *string  `json:"model,omitempty"`
	Timeout     *int     `json:"timeout,omitempty"`
	MaxTokens   *int     `json:"max_tokens,omitempty"`
	Temperature *float64 `json:"temperature,omitempty"`
}

// OpenAICompatibleConfigResponse OpenAIå…¼å®¹APIé…ç½®å“åº”
type OpenAICompatibleConfigResponse struct {
	Enabled     bool    `json:"enabled"`
	Provider    string  `json:"provider"`
	ApiKey      string  `json:"api_key"` // è„±æ•æ˜¾ç¤º
	BaseURL     string  `json:"base_url"`
	Model       string  `json:"model"`
	Timeout     int     `json:"timeout"`
	MaxTokens   int     `json:"max_tokens"`
	Temperature float64 `json:"temperature"`
}

// OpenAIProviderInfo æä¾›å•†ä¿¡æ¯
type OpenAIProviderInfo struct {
	ID           string `json:"id"`
	Name         string `json:"name"`
	Description  string `json:"description"`
	BaseURL      string `json:"base_url"`
	DefaultModel string `json:"default_model"`
}

// TestAPIRequest æµ‹è¯•APIè¯·æ±‚
type TestAPIRequest struct {
	Provider    string  `json:"provider"`
	ApiKey      string  `json:"api_key"`
	BaseURL     string  `json:"base_url"`
	Model       string  `json:"model"`
	Timeout     int     `json:"timeout"`
	Temperature float64 `json:"temperature"`
}

// TestAPIResponse æµ‹è¯•APIå“åº”
type TestAPIResponse struct {
	Success  bool   `json:"success"`
	Message  string `json:"message"`
	Response string `json:"response,omitempty"`
	Latency  int64  `json:"latency_ms,omitempty"`
}

// getOpenAICompatibleConfig è·å–OpenAIå…¼å®¹APIé…ç½®
func (h *ConfigHandler) getOpenAICompatibleConfig(c *gin.Context) {
	config := h.App.Config.OpenAICompatibleConfig
	if config == nil {
		c.JSON(http.StatusOK, gin.H{
			"code":    200,
			"message": "success",
			"data": OpenAICompatibleConfigResponse{
				Enabled:     false,
				Provider:    "openai",
				ApiKey:      "",
				BaseURL:     "https://api.openai.com/v1",
				Model:       "gpt-3.5-turbo",
				Timeout:     60,
				MaxTokens:   4000,
				Temperature: 0.7,
			},
		})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data": OpenAICompatibleConfigResponse{
			Enabled:     config.Enabled,
			Provider:    config.Provider,
			ApiKey:      maskApiKey(config.ApiKey),
			BaseURL:     config.BaseURL,
			Model:       config.Model,
			Timeout:     config.Timeout,
			MaxTokens:   config.MaxTokens,
			Temperature: config.Temperature,
		},
	})
}

// updateOpenAICompatibleConfig æ›´æ–°OpenAIå…¼å®¹APIé…ç½®
func (h *ConfigHandler) updateOpenAICompatibleConfig(c *gin.Context) {
	var req OpenAICompatibleConfigRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid request body: " + err.Error(),
		})
		return
	}

	// ç¡®ä¿é…ç½®å¯¹è±¡å­˜åœ¨
	if h.App.Config.OpenAICompatibleConfig == nil {
		h.App.Config.OpenAICompatibleConfig = &types.OpenAICompatibleConfig{
			Enabled:     false,
			Provider:    "openai",
			ApiKey:      "",
			BaseURL:     "https://api.openai.com/v1",
			Model:       "gpt-3.5-turbo",
			Timeout:     60,
			MaxTokens:   4000,
			Temperature: 0.7,
		}
	}

	config := h.App.Config.OpenAICompatibleConfig

	// æ›´æ–°é…ç½®å­—æ®µ
	if req.Enabled != nil {
		config.Enabled = *req.Enabled
		h.App.Logger.Infof("Updated OpenAI Compatible enabled: %v", config.Enabled)
	}
	if req.Provider != nil {
		config.Provider = *req.Provider
		h.App.Logger.Infof("Updated OpenAI Compatible provider: %s", config.Provider)
	}
	if req.ApiKey != nil {
		config.ApiKey = *req.ApiKey
		h.App.Logger.Infof("Updated OpenAI Compatible API Key: %s", maskApiKey(*req.ApiKey))
	}
	if req.BaseURL != nil {
		config.BaseURL = *req.BaseURL
		h.App.Logger.Infof("Updated OpenAI Compatible base URL: %s", config.BaseURL)
	}
	if req.Model != nil {
		config.Model = *req.Model
		h.App.Logger.Infof("Updated OpenAI Compatible model: %s", config.Model)
	}
	if req.Timeout != nil {
		config.Timeout = *req.Timeout
		h.App.Logger.Infof("Updated OpenAI Compatible timeout: %d", config.Timeout)
	}
	if req.MaxTokens != nil {
		config.MaxTokens = *req.MaxTokens
		h.App.Logger.Infof("Updated OpenAI Compatible max_tokens: %d", config.MaxTokens)
	}
	if req.Temperature != nil {
		config.Temperature = *req.Temperature
		h.App.Logger.Infof("Updated OpenAI Compatible temperature: %f", config.Temperature)
	}

	// ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
	if err := types.SaveConfig(h.App.Config); err != nil {
		h.App.Logger.Errorf("Failed to save config: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{
			"code":    500,
			"message": "Failed to save configuration: " + err.Error(),
		})
		return
	}

	h.App.Config.OpenAICompatibleConfig = config
	h.App.Logger.Info("âœ… OpenAI Compatible configuration updated successfully")

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "Configuration updated successfully",
		"data": OpenAICompatibleConfigResponse{
			Enabled:     config.Enabled,
			Provider:    config.Provider,
			ApiKey:      maskApiKey(config.ApiKey),
			BaseURL:     config.BaseURL,
			Model:       config.Model,
			Timeout:     config.Timeout,
			MaxTokens:   config.MaxTokens,
			Temperature: config.Temperature,
		},
	})
}

// testOpenAICompatibleAPI æµ‹è¯•OpenAIå…¼å®¹APIè¿æ¥
func (h *ConfigHandler) testOpenAICompatibleAPI(c *gin.Context) {
	var req TestAPIRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid request body: " + err.Error(),
		})
		return
	}

	// éªŒè¯å¿…è¦å‚æ•°
	if req.ApiKey == "" {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "API Key is required",
		})
		return
	}
	if req.BaseURL == "" {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Base URL is required",
		})
		return
	}

	// è®¾ç½®é»˜è®¤å€¼
	if req.Model == "" {
		req.Model = "gpt-3.5-turbo"
	}
	if req.Timeout <= 0 {
		req.Timeout = 30
	}
	if req.Temperature <= 0 {
		req.Temperature = 0.7
	}

	h.App.Logger.Infof("Testing OpenAI Compatible API: provider=%s, base_url=%s, model=%s",
		req.Provider, req.BaseURL, req.Model)

	// è°ƒç”¨æµ‹è¯•
	testResult := h.doTestOpenAIAPI(req)

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "Test completed",
		"data":    testResult,
	})
}

// doTestOpenAIAPI æ‰§è¡ŒAPIæµ‹è¯•
func (h *ConfigHandler) doTestOpenAIAPI(req TestAPIRequest) TestAPIResponse {
	startTime := time.Now()

	// æ„å»ºè¯·æ±‚
	requestBody := map[string]interface{}{
		"model": req.Model,
		"messages": []map[string]string{
			{"role": "system", "content": "You are a helpful assistant."},
			{"role": "user", "content": "Say 'OK' if you can hear me."},
		},
		"max_tokens":  50,
		"temperature": req.Temperature,
	}

	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		return TestAPIResponse{
			Success: false,
			Message: "Failed to create request: " + err.Error(),
		}
	}

	// æ„å»ºURL
	apiURL := req.BaseURL
	if !strings.HasSuffix(apiURL, "/v1") && !strings.Contains(apiURL, "/chat/completions") {
		apiURL = strings.TrimSuffix(apiURL, "/") + "/v1"
	}
	if !strings.Contains(apiURL, "/chat/completions") {
		apiURL = strings.TrimSuffix(apiURL, "/") + "/chat/completions"
	}

	httpReq, err := http.NewRequest("POST", apiURL, bytes.NewBuffer(jsonData))
	if err != nil {
		return TestAPIResponse{
			Success: false,
			Message: "Failed to create HTTP request: " + err.Error(),
		}
	}

	httpReq.Header.Set("Content-Type", "application/json")
	httpReq.Header.Set("Authorization", "Bearer "+req.ApiKey)

	client := &http.Client{
		Timeout: time.Duration(req.Timeout) * time.Second,
	}

	resp, err := client.Do(httpReq)
	if err != nil {
		return TestAPIResponse{
			Success: false,
			Message: "API request failed: " + err.Error(),
		}
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return TestAPIResponse{
			Success: false,
			Message: "Failed to read response: " + err.Error(),
		}
	}

	latency := time.Since(startTime).Milliseconds()

	if resp.StatusCode != http.StatusOK {
		return TestAPIResponse{
			Success: false,
			Message: fmt.Sprintf("API returned error (status %d): %s", resp.StatusCode, string(body)),
			Latency: latency,
		}
	}

	// è§£æå“åº”
	var apiResp struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
		} `json:"choices"`
		Error *struct {
			Message string `json:"message"`
		} `json:"error"`
	}

	if err := json.Unmarshal(body, &apiResp); err != nil {
		return TestAPIResponse{
			Success: false,
			Message: "Failed to parse response: " + err.Error(),
			Latency: latency,
		}
	}

	if apiResp.Error != nil {
		return TestAPIResponse{
			Success: false,
			Message: "API error: " + apiResp.Error.Message,
			Latency: latency,
		}
	}

	responseText := ""
	if len(apiResp.Choices) > 0 {
		responseText = apiResp.Choices[0].Message.Content
	}

	return TestAPIResponse{
		Success:  true,
		Message:  "API connection successful",
		Response: responseText,
		Latency:  latency,
	}
}

// getOpenAICompatibleProviders è·å–æ”¯æŒçš„æä¾›å•†åˆ—è¡¨
func (h *ConfigHandler) getOpenAICompatibleProviders(c *gin.Context) {
	providers := []OpenAIProviderInfo{
		{
			ID:           "openai",
			Name:         "OpenAI",
			Description:  "OpenAIå®˜æ–¹APIï¼Œæ”¯æŒGPT-3.5/GPT-4ç­‰æ¨¡å‹",
			BaseURL:      "https://api.openai.com/v1",
			DefaultModel: "gpt-3.5-turbo",
		},
		{
			ID:           "deepseek",
			Name:         "DeepSeek",
			Description:  "DeepSeekæ·±åº¦æ±‚ç´¢ï¼Œå›½äº§å¤§æ¨¡å‹",
			BaseURL:      "https://api.deepseek.com/v1",
			DefaultModel: "deepseek-chat",
		},
		{
			ID:           "qwen",
			Name:         "é€šä¹‰åƒé—®",
			Description:  "é˜¿é‡Œäº‘é€šä¹‰åƒé—®ï¼Œæ”¯æŒOpenAIå…¼å®¹æ¨¡å¼",
			BaseURL:      "https://dashscope.aliyuncs.com/compatible-mode/v1",
			DefaultModel: "qwen-turbo",
		},
		{
			ID:           "zhipu",
			Name:         "æ™ºè°±AI",
			Description:  "æ™ºè°±AI GLMç³»åˆ—æ¨¡å‹",
			BaseURL:      "https://open.bigmodel.cn/api/paas/v4/",
			DefaultModel: "glm-4-flash",
		},
		{
			ID:           "gemini",
			Name:         "Google Gemini",
			Description:  "Google Geminiæ¨¡å‹ï¼ˆé€šè¿‡OpenAIå…¼å®¹æ¥å£ï¼‰",
			BaseURL:      "https://generativelanguage.googleapis.com/v1beta/openai",
			DefaultModel: "gemini-2.0-flash",
		},
		{
			ID:           "custom",
			Name:         "è‡ªå®šä¹‰",
			Description:  "è‡ªå®šä¹‰OpenAIå…¼å®¹APIï¼ˆå¦‚one-apiã€new-apiä»£ç†ï¼‰",
			BaseURL:      "",
			DefaultModel: "",
		},
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data":    providers,
	})
}

// ========== AIæœåŠ¡çŠ¶æ€ ==========

// AIServiceStatusResponse AIæœåŠ¡çŠ¶æ€å“åº”
type AIServiceStatusResponse struct {
	Provider  string `json:"provider"`
	Name      string `json:"name"`
	Enabled   bool   `json:"enabled"`
	Available bool   `json:"available"`
	Model     string `json:"model,omitempty"`
	BaseURL   string `json:"base_url,omitempty"`
	IsPrimary bool   `json:"is_primary"`
	LastError string `json:"last_error,omitempty"`
}

// getAIServicesStatus è·å–æ‰€æœ‰AIæœåŠ¡çŠ¶æ€
func (h *ConfigHandler) getAIServicesStatus(c *gin.Context) {
	var services []AIServiceStatusResponse

	// è·å–ç”¨æˆ·é€‰æ‹©çš„é¦–é€‰æœåŠ¡
	primaryProvider := h.App.Config.PrimaryAIService

	// 1. OpenAIå…¼å®¹API
	openaiConfig := h.App.Config.OpenAICompatibleConfig
	openaiEnabled := openaiConfig != nil && openaiConfig.Enabled && openaiConfig.ApiKey != ""
	openaiService := AIServiceStatusResponse{
		Provider:  "openai_compatible",
		Name:      "è‡ªå®šä¹‰API",
		Enabled:   openaiEnabled,
		Available: openaiEnabled,
		IsPrimary: primaryProvider == "openai_compatible" && openaiEnabled,
	}
	if openaiConfig != nil {
		openaiService.Model = openaiConfig.Model
		openaiService.BaseURL = openaiConfig.BaseURL
		// æ ¹æ®Provideræ˜¾ç¤ºæ›´å‹å¥½çš„åç§°
		switch openaiConfig.Provider {
		case "openai":
			openaiService.Name = "OpenAI"
		case "deepseek":
			openaiService.Name = "DeepSeek (å…¼å®¹æ¨¡å¼)"
		case "qwen":
			openaiService.Name = "é€šä¹‰åƒé—®"
		case "zhipu":
			openaiService.Name = "æ™ºè°±AI"
		case "gemini":
			openaiService.Name = "Gemini (ä»£ç†)"
		case "custom":
			openaiService.Name = "è‡ªå®šä¹‰API"
		}
	}
	services = append(services, openaiService)

	// 2. DeepSeek
	deepseekConfig := h.App.Config.DeepSeekTransConfig
	deepseekEnabled := deepseekConfig != nil && deepseekConfig.Enabled && deepseekConfig.ApiKey != ""
	deepseekService := AIServiceStatusResponse{
		Provider:  "deepseek",
		Name:      "DeepSeek",
		Enabled:   deepseekEnabled,
		Available: deepseekEnabled,
		IsPrimary: primaryProvider == "deepseek" && deepseekEnabled,
	}
	if deepseekConfig != nil {
		deepseekService.Model = deepseekConfig.Model
		deepseekService.BaseURL = deepseekConfig.Endpoint
	}
	services = append(services, deepseekService)

	// 3. Geminiï¼ˆåŸç”Ÿï¼‰
	geminiConfig := h.App.Config.GeminiConfig
	geminiEnabled := geminiConfig != nil && geminiConfig.Enabled && (geminiConfig.ApiKey != "" || len(geminiConfig.ApiKeys) > 0)
	geminiService := AIServiceStatusResponse{
		Provider:  "gemini",
		Name:      "Geminiï¼ˆåŸç”Ÿå¤šæ¨¡æ€ï¼‰",
		Enabled:   geminiEnabled,
		Available: geminiEnabled,
		IsPrimary: primaryProvider == "gemini" && geminiEnabled,
	}
	if geminiConfig != nil {
		geminiService.Model = geminiConfig.Model
	}
	services = append(services, geminiService)

	// å¦‚æœæ²¡æœ‰è®¾ç½®é¦–é€‰æˆ–é¦–é€‰æœåŠ¡æœªå¯ç”¨ï¼Œè‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æœåŠ¡
	hasPrimary := false
	for _, svc := range services {
		if svc.IsPrimary {
			hasPrimary = true
			break
		}
	}
	if !hasPrimary {
		// è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æœåŠ¡
		for i := range services {
			if services[i].Enabled {
				services[i].IsPrimary = true
				primaryProvider = services[i].Provider
				break
			}
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data": gin.H{
			"services":         services,
			"primary_provider": primaryProvider,
			"has_available":    openaiEnabled || deepseekEnabled || geminiEnabled,
		},
	})
}

// SetPrimaryAIServiceRequest è®¾ç½®é¦–é€‰AIæœåŠ¡è¯·æ±‚
type SetPrimaryAIServiceRequest struct {
	Provider string `json:"provider"` // openai_compatible, deepseek, gemini
}

// setPrimaryAIService è®¾ç½®é¦–é€‰AIæœåŠ¡
func (h *ConfigHandler) setPrimaryAIService(c *gin.Context) {
	var req SetPrimaryAIServiceRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid request body: " + err.Error(),
		})
		return
	}

	// éªŒè¯æä¾›å•†æ˜¯å¦æœ‰æ•ˆ
	validProviders := map[string]bool{
		"openai_compatible": true,
		"deepseek":          true,
		"gemini":            true,
	}
	if !validProviders[req.Provider] {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid provider. Must be one of: openai_compatible, deepseek, gemini",
		})
		return
	}

	// æ£€æŸ¥è¯¥æœåŠ¡æ˜¯å¦å·²å¯ç”¨
	isEnabled := false
	switch req.Provider {
	case "openai_compatible":
		cfg := h.App.Config.OpenAICompatibleConfig
		isEnabled = cfg != nil && cfg.Enabled && cfg.ApiKey != ""
	case "deepseek":
		cfg := h.App.Config.DeepSeekTransConfig
		isEnabled = cfg != nil && cfg.Enabled && cfg.ApiKey != ""
	case "gemini":
		cfg := h.App.Config.GeminiConfig
		isEnabled = cfg != nil && cfg.Enabled && (cfg.ApiKey != "" || len(cfg.ApiKeys) > 0)
	}

	if !isEnabled {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "è¯¥AIæœåŠ¡æœªå¯ç”¨æˆ–æœªé…ç½®ï¼Œè¯·å…ˆé…ç½®å¹¶å¯ç”¨è¯¥æœåŠ¡",
		})
		return
	}

	// æ›´æ–°é…ç½®
	h.App.Config.PrimaryAIService = req.Provider

	// ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
	if err := types.SaveConfig(h.App.Config); err != nil {
		h.App.Logger.Errorf("Failed to save config: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{
			"code":    500,
			"message": "Failed to save configuration: " + err.Error(),
		})
		return
	}

	h.App.Logger.Infof("âœ… é¦–é€‰AIæœåŠ¡å·²æ›´æ–°ä¸º: %s", req.Provider)

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "é¦–é€‰AIæœåŠ¡è®¾ç½®æˆåŠŸ",
		"data": gin.H{
			"primary_provider": req.Provider,
		},
	})
}

// ========== Gemini åŸç”Ÿé…ç½®ï¼ˆç”¨äºå…ƒæ•°æ®ç”Ÿæˆï¼‰ ==========

// GeminiConfigRequest Geminié…ç½®è¯·æ±‚
type GeminiConfigRequest struct {
	Enabled           *bool    `json:"enabled,omitempty"`
	ApiKey            *string  `json:"api_key,omitempty"`        // å•ä¸ª API Keyï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
	ApiKeys           []string `json:"api_keys,omitempty"`       // å¤šä¸ª API Keyï¼ˆç”¨äºè½®è¯¢ï¼‰
	ClearApiKeys      *bool    `json:"clear_api_keys,omitempty"` // æ˜¯å¦æ¸…ç©ºæ‰€æœ‰ API Keys
	Model             *string  `json:"model,omitempty"`
	Timeout           *int     `json:"timeout,omitempty"`
	MaxTokens         *int     `json:"max_tokens,omitempty"`
	UseForMetadata    *bool    `json:"use_for_metadata,omitempty"`
	AnalyzeVideo      *bool    `json:"analyze_video,omitempty"`
	VideoSampleFrames *int     `json:"video_sample_frames,omitempty"`
}

// GeminiConfigResponse Geminié…ç½®å“åº”
type GeminiConfigResponse struct {
	Enabled           bool     `json:"enabled"`
	ApiKey            string   `json:"api_key"`        // è„±æ•æ˜¾ç¤ºï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
	ApiKeys           []string `json:"api_keys"`       // å¤šä¸ª API Keyï¼ˆè„±æ•æ˜¾ç¤ºï¼‰
	ApiKeysCount      int      `json:"api_keys_count"` // API Key æ•°é‡
	Model             string   `json:"model"`
	Timeout           int      `json:"timeout"`
	MaxTokens         int      `json:"max_tokens"`
	UseForMetadata    bool     `json:"use_for_metadata"`
	AnalyzeVideo      bool     `json:"analyze_video"`
	VideoSampleFrames int      `json:"video_sample_frames"`
}

// getGeminiConfig è·å–Geminié…ç½®
func (h *ConfigHandler) getGeminiConfig(c *gin.Context) {
	config := h.App.Config.GeminiConfig
	if config == nil {
		c.JSON(http.StatusOK, gin.H{
			"code":    200,
			"message": "success",
			"data": GeminiConfigResponse{
				Enabled:           false,
				ApiKey:            "",
				ApiKeys:           []string{},
				ApiKeysCount:      0,
				Model:             "gemini-2.0-flash",
				Timeout:           120,
				MaxTokens:         8000,
				UseForMetadata:    true,
				AnalyzeVideo:      true,
				VideoSampleFrames: 0,
			},
		})
		return
	}

	// è„±æ•æ˜¾ç¤ºå•ä¸ª API Key
	apiKeyMasked := ""
	if config.ApiKey != "" {
		if len(config.ApiKey) > 10 {
			apiKeyMasked = config.ApiKey[:6] + "..." + config.ApiKey[len(config.ApiKey)-4:]
		} else {
			apiKeyMasked = "***"
		}
	}

	// è„±æ•æ˜¾ç¤ºå¤šä¸ª API Keys
	apiKeysMasked := make([]string, len(config.ApiKeys))
	for i, key := range config.ApiKeys {
		if len(key) > 10 {
			apiKeysMasked[i] = key[:6] + "..." + key[len(key)-4:]
		} else {
			apiKeysMasked[i] = "***"
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data": GeminiConfigResponse{
			Enabled:           config.Enabled,
			ApiKey:            apiKeyMasked,
			ApiKeys:           apiKeysMasked,
			ApiKeysCount:      config.GetApiKeysCount(),
			Model:             config.Model,
			Timeout:           config.Timeout,
			MaxTokens:         config.MaxTokens,
			UseForMetadata:    config.UseForMetadata,
			AnalyzeVideo:      config.AnalyzeVideo,
			VideoSampleFrames: config.VideoSampleFrames,
		},
	})
}

// updateGeminiConfig æ›´æ–°Geminié…ç½®
func (h *ConfigHandler) updateGeminiConfig(c *gin.Context) {
	var req GeminiConfigRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "Invalid request body: " + err.Error(),
		})
		return
	}

	// ç¡®ä¿é…ç½®å¯¹è±¡å­˜åœ¨
	if h.App.Config.GeminiConfig == nil {
		h.App.Config.GeminiConfig = &types.GeminiConfig{
			Enabled:           false,
			ApiKey:            "",
			ApiKeys:           []string{},
			Model:             "gemini-2.0-flash",
			Timeout:           120,
			MaxTokens:         8000,
			UseForMetadata:    true,
			AnalyzeVideo:      true,
			VideoSampleFrames: 0,
		}
	}

	config := h.App.Config.GeminiConfig

	// æ›´æ–°é…ç½®å­—æ®µ
	if req.Enabled != nil {
		config.Enabled = *req.Enabled
	}
	if req.ApiKey != nil {
		config.ApiKey = *req.ApiKey
	}
	// å¤„ç†æ¸…ç©º API Keys çš„è¯·æ±‚
	if req.ClearApiKeys != nil && *req.ClearApiKeys {
		config.ApiKeys = []string{}
		config.ApiKey = ""
		h.App.Logger.Info("ğŸ—‘ï¸ Clearing all Gemini API Keys")
	} else if len(req.ApiKeys) > 0 {
		config.ApiKeys = req.ApiKeys
	}
	if req.Model != nil {
		config.Model = *req.Model
	}
	if req.Timeout != nil {
		config.Timeout = *req.Timeout
	}
	if req.MaxTokens != nil {
		config.MaxTokens = *req.MaxTokens
	}
	if req.UseForMetadata != nil {
		config.UseForMetadata = *req.UseForMetadata
	}
	if req.AnalyzeVideo != nil {
		config.AnalyzeVideo = *req.AnalyzeVideo
	}
	if req.VideoSampleFrames != nil {
		config.VideoSampleFrames = *req.VideoSampleFrames
	}

	// ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
	if err := types.SaveConfig(h.App.Config); err != nil {
		h.App.Logger.Errorf("Failed to save config: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{
			"code":    500,
			"message": "Failed to save configuration: " + err.Error(),
		})
		return
	}

	h.App.Config.GeminiConfig = config
	h.App.Logger.Infof("âœ… Gemini configuration updated successfully (API Keys: %d)", config.GetApiKeysCount())

	// è„±æ•æ˜¾ç¤ºå¤šä¸ª API Keys
	apiKeysMasked := make([]string, len(config.ApiKeys))
	for i, key := range config.ApiKeys {
		if len(key) > 10 {
			apiKeysMasked[i] = key[:6] + "..." + key[len(key)-4:]
		} else {
			apiKeysMasked[i] = "***"
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "Configuration updated successfully",
		"data": GeminiConfigResponse{
			Enabled:           config.Enabled,
			ApiKey:            maskApiKey(config.ApiKey),
			ApiKeys:           apiKeysMasked,
			ApiKeysCount:      config.GetApiKeysCount(),
			Model:             config.Model,
			Timeout:           config.Timeout,
			MaxTokens:         config.MaxTokens,
			UseForMetadata:    config.UseForMetadata,
			AnalyzeVideo:      config.AnalyzeVideo,
			VideoSampleFrames: config.VideoSampleFrames,
		},
	})
}

// ========== Gemini API Key éªŒè¯ ==========

// ApiKeyValidationResult å•ä¸ª API Key çš„éªŒè¯ç»“æœ
type ApiKeyValidationResult struct {
	Key     string `json:"key"`     // è„±æ•åçš„ Key
	Index   int    `json:"index"`   // Key çš„ç´¢å¼•
	Valid   bool   `json:"valid"`   // æ˜¯å¦æœ‰æ•ˆ
	Message string `json:"message"` // éªŒè¯æ¶ˆæ¯
}

// ValidateGeminiApiKeysResponse éªŒè¯å“åº”
type ValidateGeminiApiKeysResponse struct {
	TotalKeys   int                      `json:"total_keys"`   // æ€» Key æ•°é‡
	ValidKeys   int                      `json:"valid_keys"`   // æœ‰æ•ˆ Key æ•°é‡
	InvalidKeys int                      `json:"invalid_keys"` // æ— æ•ˆ Key æ•°é‡
	Results     []ApiKeyValidationResult `json:"results"`      // æ¯ä¸ª Key çš„éªŒè¯ç»“æœ
	AutoRemoved int                      `json:"auto_removed"` // è‡ªåŠ¨ç§»é™¤çš„æ— æ•ˆ Key æ•°é‡
}

// validateGeminiApiKeys éªŒè¯æ‰€æœ‰ Gemini API Keys
func (h *ConfigHandler) validateGeminiApiKeys(c *gin.Context) {
	config := h.App.Config.GeminiConfig
	if config == nil || len(config.ApiKeys) == 0 {
		c.JSON(http.StatusOK, gin.H{
			"code":    200,
			"message": "No API Keys configured",
			"data": ValidateGeminiApiKeysResponse{
				TotalKeys:   0,
				ValidKeys:   0,
				InvalidKeys: 0,
				Results:     []ApiKeyValidationResult{},
			},
		})
		return
	}

	h.App.Logger.Info("ğŸ” å¼€å§‹éªŒè¯ Gemini API Keys...")

	// å¹¶å‘éªŒè¯æ‰€æœ‰ API Keys
	var wg sync.WaitGroup
	results := make([]ApiKeyValidationResult, len(config.ApiKeys))

	for i, apiKey := range config.ApiKeys {
		wg.Add(1)
		go func(index int, key string) {
			defer wg.Done()

			result := ApiKeyValidationResult{
				Key:   maskApiKey(key),
				Index: index,
			}

			// åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯æµ‹è¯•è¿æ¥
			ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
			defer cancel()

			client, err := genai.NewClient(ctx, option.WithAPIKey(key))
			if err != nil {
				result.Valid = false
				result.Message = fmt.Sprintf("åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: %v", err)
				results[index] = result
				return
			}
			defer client.Close()

			// æµ‹è¯• API è°ƒç”¨
			model := client.GenerativeModel(config.Model)
			model.SetMaxOutputTokens(10)
			model.SetTemperature(0.1)

			_, err = model.GenerateContent(ctx, genai.Text("Hi"))
			if err != nil {
				result.Valid = false
				errMsg := err.Error()
				if strings.Contains(errMsg, "leaked") {
					result.Message = "âš ï¸ API Key å·²æ³„éœ²ï¼Œè¯·æ›´æ¢"
				} else if strings.Contains(errMsg, "invalid") || strings.Contains(errMsg, "API key not valid") {
					result.Message = "âŒ API Key æ— æ•ˆ"
				} else if strings.Contains(errMsg, "quota") {
					result.Message = "âš ï¸ é…é¢å·²ç”¨å°½"
				} else if strings.Contains(errMsg, "403") {
					result.Message = "âŒ è®¿é—®è¢«æ‹’ç»: " + errMsg
				} else {
					result.Message = "âŒ éªŒè¯å¤±è´¥: " + errMsg
				}
			} else {
				result.Valid = true
				result.Message = "âœ… æœ‰æ•ˆ"
			}

			results[index] = result
		}(i, apiKey)
	}

	wg.Wait()

	// ç»Ÿè®¡ç»“æœ
	validCount := 0
	invalidCount := 0
	for _, r := range results {
		if r.Valid {
			validCount++
		} else {
			invalidCount++
		}
	}

	h.App.Logger.Infof("ğŸ” Gemini API Keys éªŒè¯å®Œæˆ: %d æœ‰æ•ˆ, %d æ— æ•ˆ", validCount, invalidCount)

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": fmt.Sprintf("éªŒè¯å®Œæˆ: %d æœ‰æ•ˆ, %d æ— æ•ˆ", validCount, invalidCount),
		"data": ValidateGeminiApiKeysResponse{
			TotalKeys:   len(config.ApiKeys),
			ValidKeys:   validCount,
			InvalidKeys: invalidCount,
			Results:     results,
			AutoRemoved: 0,
		},
	})
}

// getGeminiModels è·å– Gemini å¯ç”¨æ¨¡å‹åˆ—è¡¨
func (h *ConfigHandler) getGeminiModels(c *gin.Context) {
	config := h.App.Config.GeminiConfig
	if config == nil || len(config.ApiKeys) == 0 {
		c.JSON(http.StatusBadRequest, gin.H{
			"code":    400,
			"message": "No API Keys configured",
		})
		return
	}

	// ä½¿ç”¨ç¬¬ä¸€ä¸ª API Key è·å–æ¨¡å‹åˆ—è¡¨
	apiKey := config.ApiKeys[0]

	ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
	defer cancel()

	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{
			"code":    500,
			"message": "åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: " + err.Error(),
		})
		return
	}
	defer client.Close()

	// è·å–æ¨¡å‹åˆ—è¡¨
	iter := client.ListModels(ctx)
	var models []string
	for {
		m, err := iter.Next()
		if err != nil {
			break
		}
		// åªè¿”å›æ”¯æŒç”Ÿæˆå†…å®¹çš„æ¨¡å‹
		if strings.Contains(m.Name, "gemini") {
			// æå–æ¨¡å‹åç§°ï¼ˆå»æ‰ "models/" å‰ç¼€ï¼‰
			modelName := strings.TrimPrefix(m.Name, "models/")
			models = append(models, modelName)
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"code":    200,
		"message": "success",
		"data": gin.H{
			"models": models,
		},
	})
}
